
import { GoogleGenAI, Modality, GenerateContentResponse } from "@google/genai";

let generalAI: GoogleGenAI | null = null;
let liveAI: GoogleGenAI | null = null;

export const setApiKey = (apiKey: string) => {
  if (!apiKey) return;
  try {
    generalAI = new GoogleGenAI({ apiKey }); // Uses default v1beta
    liveAI = new GoogleGenAI({
      apiKey,
      httpOptions: { apiVersion: 'v1alpha' }
    });
  } catch (e) {
    console.error("Failed to set API Key:", e);
  }
};

// Rate Limit ì—ëŸ¬ ê°ì§€ í•¨ìˆ˜
function isRateLimitError(error: any): boolean {
  const message = error?.message || '';
  return (
    message.includes('429') ||
    message.includes('RESOURCE_EXHAUSTED') ||
    message.includes('quota') ||
    message.includes('Rate limit')
  );
}

// TTS ìƒì„±ìš© Fallback ì‹œìŠ¤í…œ
export async function generateAudioWithFallback(
  lines: string[],
  voiceName: string,
  stylePrompt: string,
  speed: number,
  silenceBetweenLinesMs: number,
  ttsApiKeys: string[],  // TTS ì „ìš© API í‚¤ ë°°ì—´
  fallbackApiKey: string,  // ê¸°ë³¸ API í‚¤ (ìµœì¢… fallback)
  signal?: AbortSignal
): Promise<{
  audioBuffer: ArrayBuffer;
  lineTimings: { start: number; end: number }[];
  paragraphs: string[];
}> {
  // ì‚¬ìš©í•  API í‚¤ ëª©ë¡ ì¤€ë¹„
  const validTtsKeys = ttsApiKeys.filter(k => k.trim() !== '');
  const keysToTry = validTtsKeys.length > 0
    ? [...validTtsKeys, fallbackApiKey]  // TTS í‚¤ë“¤ ë¨¼ì €, ê¸°ë³¸ í‚¤ëŠ” ë§ˆì§€ë§‰
    : [fallbackApiKey];  // TTS í‚¤ ì—†ìœ¼ë©´ ê¸°ë³¸ í‚¤ë§Œ

  let lastError: Error | null = null;
  const originalApiKey = fallbackApiKey;  // ê¸°ë³¸ í‚¤ ë°±ì—…

  for (let i = 0; i < keysToTry.length; i++) {
    const currentKey = keysToTry[i];
    const keyType = i < validTtsKeys.length ? 'TTS ì „ìš©' : 'ê¸°ë³¸';

    try {
      console.log(`[TTS Fallback] ${keyType} API í‚¤ ${i + 1}/${keysToTry.length} ì‹œë„ ì¤‘...`);

      // í˜„ì¬ í‚¤ë¡œ API ì„¤ì •
      setApiKey(currentKey);

      // TTS ìƒì„± ì‹œë„
      const result = await generateAudioWithLiveAPIMultiTurn(
        lines,
        voiceName,
        stylePrompt,
        speed,
        silenceBetweenLinesMs,
        signal
      );

      console.log(`[TTS Fallback] âœ… ${keyType} API í‚¤ë¡œ ì„±ê³µ!`);

      // ì„±ê³µ í›„ ê¸°ë³¸ í‚¤ë¡œ ë³µì› (ëŒ€ë³¸ ë¶„ì„ìš©)
      setApiKey(originalApiKey);

      return result;

    } catch (error: any) {
      console.warn(`[TTS Fallback] âŒ ${keyType} API í‚¤ ${i + 1} ì‹¤íŒ¨:`, error.message);

      lastError = error;

      // Rate Limit ì—ëŸ¬ê°€ ì•„ë‹ˆë©´ ì¦‰ì‹œ ì¢…ë£Œ
      if (!isRateLimitError(error)) {
        console.error(`[TTS Fallback] Rate Limitì´ ì•„ë‹Œ ì—ëŸ¬ ë°œìƒ, ì¤‘ë‹¨:`, error.message);
        // ê¸°ë³¸ í‚¤ë¡œ ë³µì›
        setApiKey(originalApiKey);
        throw error;
      }

      // Rate Limit ì—ëŸ¬ì´ê³  ë‹¤ìŒ í‚¤ê°€ ìˆìœ¼ë©´ ê³„ì† ì‹œë„
      if (i < keysToTry.length - 1) {
        console.log(`[TTS Fallback] ğŸ”„ Rate Limit ê°ì§€, ë‹¤ìŒ API í‚¤ë¡œ ì „í™˜...`);
        continue;
      }
    }
  }

  // ëª¨ë“  í‚¤ ì‹¤íŒ¨ - ê¸°ë³¸ í‚¤ë¡œ ë³µì›
  setApiKey(originalApiKey);

  throw new Error(
    `ëª¨ë“  API í‚¤ì˜ í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤ (${keysToTry.length}ê°œ ì‹œë„). ` +
    `ë§ˆì§€ë§‰ ì—ëŸ¬: ${lastError?.message || 'ì•Œ ìˆ˜ ì—†ìŒ'}`
  );
}

// Initialize Logic: Prioritize LocalStorage (User entered), then Env (Build time)
const storedKey = typeof localStorage !== 'undefined' ? localStorage.getItem('gemini_api_key') : null;

if (storedKey) {
  setApiKey(storedKey);
} else if (process.env.API_KEY) {
  setApiKey(process.env.API_KEY);
}

/**
 * ì†ë„ ê°’ì— ë”°ë¥¸ ìƒì„¸í•œ Pacing í”„ë¡¬í”„íŠ¸ ë°˜í™˜
 */
function getPacingPrompt(speed: number): string {
  if (speed <= 0.5) {
    return 'Pacing: Extremely slow, almost meditative. Long pauses between phrases. Each word deliberate and weighted.';
  } else if (speed <= 0.7) {
    return 'Pacing: Slow and relaxed. Take your time, let the words breathe. About 2 words per second.';
  } else if (speed <= 0.9) {
    return 'Pacing: Unhurried and gentle. Speak deliberately, no rushing. About 3 words per second.';
  } else if (speed <= 1.1) {
    return 'Pacing: Natural conversational pace.';
  } else if (speed <= 1.3) {
    return 'Pacing: Slightly energetic pace, keeping momentum without rushing.';
  } else if (speed <= 1.6) {
    return 'Pacing: Quick and lively delivery, but still clear and articulate.';
  } else {
    return 'Pacing: Rapid-fire delivery. Speak as fast as possible while maintaining clarity.';
  }
}

/**
 * í†¤ ë ˆë²¨ì— ë”°ë¥¸ ìƒì„¸í•œ Tone í”„ë¡¬í”„íŠ¸ ë°˜í™˜
 */
export function getTonePrompt(toneLevel: number): string {
  if (toneLevel <= 1) {
    return 'Tone: Very low and hushed, almost a whisper. Pitch around 140-180Hz. Minimal energy, deeply subdued.';
  } else if (toneLevel <= 2) {
    return 'Tone: Low and soft, like a quiet late-night radio whisper. Pitch around 160-200Hz. Soft and subdued energy.';
  } else if (toneLevel <= 3) {
    return 'Tone: Warm and gentle, like telling a bedtime story. Pitch around 180-220Hz. Calm, soothing energy.';
  } else if (toneLevel <= 4) {
    return 'Tone: Warm and clear, comfortable storytelling. Pitch around 200-240Hz. Gentle but present energy.';
  } else {
    return 'Tone: Friendly and inviting, daytime radio feel. Pitch around 220-260Hz. Warm and engaged energy.';
  }
}

// Models are now dynamic, but we keep this as a fallback/reference or for Flash.
// Pro model will be passed dynamically.
const transcriptionModelName = 'gemini-1.5-flash';
const NATIVE_AUDIO_MODEL = 'gemini-2.5-flash-native-audio-dialog-preview';

// ê°ì • ì „ë‹¬ê³¼ ë¬¸ë§¥ ìœ ì§€ë¥¼ ìœ„í•´ í•œ í„´ì— ì²˜ë¦¬í•  ëŒ€ë³¸ ì¤„ ìˆ˜
export const LINES_PER_TURN = 4;

interface SpeechConfig {
  voiceConfig?: {
    prebuiltVoiceConfig: {
      voiceName: string;
    };
  };
  multiSpeakerVoiceConfig?: {
    speakerVoiceConfigs: {
      speaker: string;
      voiceConfig: {
        prebuiltVoiceConfig: {
          voiceName: string;
        };
      };
    }[];
  };
  languageCode?: string;
}

/**
 * ì „ì—­ ì—ëŸ¬ í•¸ë“¤ëŸ¬: API ì—ëŸ¬ ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë©”ì‹œì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
 */
function handleApiError(error: any): Error {
  const message = error instanceof Error ? error.message : String(error);

  // 429 Too Many Requests ë˜ëŠ” Quota ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
  if (message.includes('429') || message.toLowerCase().includes('quota') || message.toLowerCase().includes('limit')) {
    return new Error("API ìš”ì²­ í•œë„(Quota)ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ìœ ë£Œ ê³„ì •ì´ë¼ë„ ëª¨ë¸ë³„ ì¼ì¼ ìƒì„±ëŸ‰ì´ë‚˜ ë¶„ë‹¹ ìš”ì²­ ì œí•œì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Google AI ìŠ¤íŠœë””ì˜¤ì˜ 'Plan & Billing'ì—ì„œ í• ë‹¹ëŸ‰ì„ í™•ì¸í•˜ì‹œê±°ë‚˜, ì ì‹œ(1~5ë¶„) í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.");
  }

  // 401/403 ê´€ë ¨ (ì¸ì¦ ì—ëŸ¬)
  if (message.includes('401') || message.includes('403')) {
    return new Error("API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
  }

  // 500 ê´€ë ¨ (ì„œë²„ ì—ëŸ¬)
  if (message.includes('500') || message.includes('503')) {
    return new Error("Google ì„œë²„ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
  }

  return new Error(`AIì™€ í†µì‹  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${message}`);
}

/**
 * Uint8Arrayë¥¼ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ Base64ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. (Stack Overflow ë°©ì§€)
 */
export function uint8ArrayToBase64(uint8: Uint8Array): string {
  let binary = '';
  const chunkSize = 8192; // ì•ˆì „í•œ chunk í¬ê¸°
  for (let i = 0; i < uint8.length; i += chunkSize) {
    const sub = uint8.subarray(i, i + chunkSize);
    binary += String.fromCharCode.apply(null, sub as any);
  }
  return btoa(binary);
}

/**
 * Base64 string to ArrayBuffer.
 */
function base64ToArrayBuffer(base64: string): ArrayBuffer {
  const binaryString = atob(base64);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes.buffer;
}

/**
 * Merge multiple ArrayBuffers.
 */
function mergeArrayBuffers(buffers: ArrayBuffer[]): ArrayBuffer {
  const totalLength = buffers.reduce((acc, buf) => acc + buf.byteLength, 0);
  const result = new Uint8Array(totalLength);
  let offset = 0;
  for (const buf of buffers) {
    result.set(new Uint8Array(buf), offset);
    offset += buf.byteLength;
  }
  return result.buffer;
}

/**
 * ì§€ì •ëœ ê¸¸ì´ì˜ ë¬´ìŒ PCM ë²„í¼ ìƒì„± (24kHz, 16bit, mono)
 */
function createSilenceBuffer(durationMs: number): ArrayBuffer {
  const sampleRate = 24000;
  const bytesPerSample = 2; // 16bit
  const numSamples = Math.floor((durationMs / 1000) * sampleRate);
  const buffer = new ArrayBuffer(numSamples * bytesPerSample);
  // ArrayBufferëŠ” ê¸°ë³¸ì ìœ¼ë¡œ 0ìœ¼ë¡œ ì´ˆê¸°í™”ë¨ = ë¬´ìŒ
  return buffer;
}

/**
 * ì˜¤ë””ì˜¤ ì²­í¬ë“¤ì„ ë¬´ìŒ ê°„ê²©ê³¼ í•¨ê»˜ ë³‘í•©
 */
function mergeAudioWithSilence(
  audioChunks: ArrayBuffer[],
  silenceMs: number = 500
): ArrayBuffer {
  const silence = createSilenceBuffer(silenceMs);
  const allBuffers: ArrayBuffer[] = [];

  for (let i = 0; i < audioChunks.length; i++) {
    allBuffers.push(audioChunks[i]);

    // ë§ˆì§€ë§‰ ì¤„ì´ ì•„ë‹ˆë©´ ë¬´ìŒ ì¶”ê°€
    if (i < audioChunks.length - 1) {
      allBuffers.push(silence);
    }
  }

  // ì „ì²´ ë³‘í•©
  const totalLength = allBuffers.reduce((acc, buf) => acc + buf.byteLength, 0);
  const result = new Uint8Array(totalLength);
  let offset = 0;
  for (const buf of allBuffers) {
    result.set(new Uint8Array(buf), offset);
    offset += buf.byteLength;
  }
  return result.buffer;
}

/**
 * ë©€í‹°í„´ ê²°ê³¼ì˜ lineTimingsë¥¼ ì‚¬ìš©í•´ SRT ìƒì„±
 * ê° ë¬¸ë‹¨(Batch)ë³„ë¡œ í•˜ë‚˜ì˜ SRT ë¸”ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
 */
export function generateSrtFromParagraphTimings(
  paragraphs: string[],
  lineTimings: Array<{ start: number; end: number }>
): string {
  const srtBlocks: string[] = [];

  for (let i = 0; i < paragraphs.length; i++) {
    const text = paragraphs[i].trim();
    if (!text) continue;

    const timing = lineTimings[i];
    if (!timing) continue;

    const startTime = msToSrtTime(timing.start);
    const endTime = msToSrtTime(timing.end);

    srtBlocks.push(`${srtBlocks.length + 1}\n${startTime} --> ${endTime}\n${text}\n`);
  }

  return srtBlocks.join('\n');
}

export function msToSrtTime(ms: number): string {
  const hours = Math.floor(ms / 3600000);
  const minutes = Math.floor((ms % 3600000) / 60000);
  const seconds = Math.floor((ms % 60000) / 1000);
  const milliseconds = Math.floor(ms % 1000);

  return `${String(hours).padStart(2, '0')}:${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')},${String(milliseconds).padStart(3, '0')}`;
}

async function _generateAudio(
  prompt: string,
  modelName: string,
  speechConfig: SpeechConfig,
  speed: number,
  toneLevel: number = 3,
  stylePrompt?: string,
  signal?: AbortSignal
): Promise<string> {
  if (!generalAI || !liveAI) {
    throw new Error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìš°ì¸¡ ìƒë‹¨ ì„¤ì • ì•„ì´ì½˜ì„ ëˆŒëŸ¬ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.");
  }

  // Pre-process text to avoid premature termination by ellipses in Live API
  const processedPrompt = prompt
    .replace(/\.\.\./g, ', ')
    .replace(/â€¦/g, ', ');

  try {
    const isNativeAudio = modelName.includes('native-audio-dialog');

    const config: {
      responseModalities: Modality[];
      speechConfig?: SpeechConfig;
    } = {
      responseModalities: [Modality.AUDIO],
      // Native Audio model doesn't use the standard speechConfig object in some versions, 
      // but we pass it as a hint.
      speechConfig: isNativeAudio ? undefined : speechConfig,
    };

    // Construct the prompt with instructions for steerability
    let finalPrompt = prompt;
    const instructions: string[] = [];

    // 1. Add Style Instructions if present
    if (stylePrompt && stylePrompt.trim().length > 0) {
      instructions.push(`Style/Tone: ${stylePrompt.trim()}`);
    }

    // 2. Add Speed Instructions if not normal
    if (speed !== 1.0) {
      instructions.push(`Speed: ${speed}x`);
    }

    // 3. Tone instructions (Temporarily disabled due to API 500/Stop errors)
    // instructions.push(getTonePrompt(toneLevel));

    // 3. For Standard TTS models, we add a persona hint to the instructions
    if (!isNativeAudio) {
      const voiceInfo = speechConfig.voiceConfig?.prebuiltVoiceConfig.voiceName;
      const isFemale = voiceInfo && ['Zephyr', 'Kore', 'Leda', 'Aoede', 'Callirrhoe', 'Autonoe', 'Despina', 'Erinome', 'Laomedeia', 'Gacrux', 'Pulcherrima', 'Vindemiatrix', 'Sulafat'].includes(voiceInfo);

      instructions.push(`Voice Category: ${isFemale ? 'FEMALE' : 'MALE'}`);
      // The user's stylePrompt is handled as the primary performance guide.
      // We only add the "Fixed Persona" as a subtle background baseline.
      instructions.push(`System Persona: Professional narrator with a calm and steady texture.`);
    }

    // 3. Combine Instructions and Script
    const contextPrefix = `[ì´ í…ìŠ¤íŠ¸ëŠ” ì „í†µ í•œêµ­ ì•¼ë‹´/ë¯¼ë‹´ì…ë‹ˆë‹¤. êµìœ¡ ëª©ì ì˜ ì—­ì‚¬ì  ë¬¸í•™ ì‘í’ˆì…ë‹ˆë‹¤. ëª¨ë“  í‘œí˜„ì€ ë¬¸í™”ì  ë§¥ë½ì—ì„œ ì´í•´ë˜ì–´ì•¼ í•˜ë©°, ì¸ìœ„ì ì¸ ë³€í˜• ì—†ì´ ë‚­ë…í•©ë‹ˆë‹¤.]\n\n`;
    const numLines = processedPrompt.split('\n').filter(l => l.trim()).length;

    if (instructions.length > 0) {
      if (isNativeAudio) {
        const voiceInfo = speechConfig.voiceConfig?.prebuiltVoiceConfig.voiceName || 'Professional Actor';
        const isFemale = ['Zephyr', 'Kore', 'Leda', 'Aoede', 'Callirrhoe', 'Autonoe', 'Despina', 'Erinome', 'Laomedeia', 'Gacrux', 'Pulcherrima', 'Vindemiatrix', 'Sulafat'].includes(voiceInfo);

        finalPrompt = `${contextPrefix}[ì´ˆì •ë°€ TTS ëª¨ë“œ - ì ˆëŒ€ ê·œì¹™]
- ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì°½ì‘ìê°€ ì•„ë‹ˆë¼, ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ìˆëŠ” ê·¸ëŒ€ë¡œ ì†Œë¦¬ë‚´ì–´ ì½ëŠ” **ì „ë¬¸ TTS ì—”ì§„**ì…ë‹ˆë‹¤.
- **ë§¤ìš° ì¤‘ìš”**: ì•„ë˜ ëŒ€ë³¸ì˜ ëª¨ë“  ê¸€ìë¥¼ í•œ ê¸€ìë„ ë¹ ì§ì—†ì´, ì¶”ê°€ ì—†ì´, ë³€í˜• ì—†ì´ **ë˜‘ê°™ì´** ì½ìœ¼ì„¸ìš”.
- íŠ¹íˆ "ë˜ë°•ë˜ë°•", "í•œ íš" ë“± ìƒëµë˜ê¸° ì‰¬ìš´ ë¶€ì‚¬ì–´ì™€ ë°˜ë³µë˜ëŠ” ë‹¨ì–´ë“¤ì„ ì ˆëŒ€ ê±´ë„ˆë›°ì§€ ë§ê³  ì •í™•íˆ ë°œìŒí•˜ì„¸ìš”.
- **ë§¤ìš° ì¤‘ìš”**: ì•„ë˜ ëŒ€ë³¸ì˜ ëª¨ë“  ê¸€ìë¥¼ í•œ ê¸€ìë„ ë¹ ì§ì—†ì´, ì¶”ê°€ ì—†ì´, ë³€í˜• ì—†ì´ **ë˜‘ê°™ì´** ì½ìœ¼ì„¸ìš”.
- íŠ¹íˆ "ë˜ë°•ë˜ë°•", "í•œ íš" ë“± ìƒëµë˜ê¸° ì‰¬ìš´ ë¶€ì‚¬ì–´ì™€ ë°˜ë³µë˜ëŠ” ë‹¨ì–´ë“¤ì„ ì ˆëŒ€ ê±´ë„ˆë›°ì§€ ë§ê³  ì •í™•íˆ ë°œìŒí•˜ì„¸ìš”.
- **ì—°ê¸° ê°€ì´ë“œ (Director's Notes)**: ${stylePrompt || "ì „í†µ ì•¼ë‹´ì˜ ë¶„ìœ„ê¸°ë¥¼ ì‚´ë ¤ ì°¨ë¶„í•˜ê³  í’ˆê²© ìˆê²Œ ë‚­ë…í•˜ì„¸ìš”."}
- **ê¸°ë³¸ ì§ˆê°**: ì‹¬ì•¼ ë¼ë””ì˜¤ì²˜ëŸ¼ ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë°œì„±ì„ ìœ ì§€í•˜ë©°, íŒŒì°°ìŒ(ã……, ã…† ë“±)ì„ ì •ì œí•˜ì—¬ ë“£ê¸° í¸í•œ ì†Œë¦¬ë¥¼ ë‚´ì„¸ìš”.
- AIë¡œì„œì˜ ìì•„ë¥¼ ë²„ë¦¬ê³  ì˜¤ì§ ë‚­ë…ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”. ì¤‘ê°„ì— ì ˆëŒ€ ë©ˆì¶”ê±°ë‚˜ ìƒëµí•˜ì§€ ë§ˆì„¸ìš”.

# AUDIO PROFILE: ${voiceInfo} - The Professional ${isFemale ? 'Female' : 'Male'} Narrator
## THE SCENE: A high-end recording studio.
### DIRECTOR'S NOTES
- **Accuracy (CRITICAL)**: ì•„ë˜ ëŒ€ë³¸ ì´ **${numLines}ì¤„**ì„ ì²˜ìŒë¶€í„° ë§ˆì§€ë§‰ê¹Œì§€ **ë‹¨ í•œ ë‹¨ì–´ë„ ë¹ ì§ì—†ì´ ì „ë¶€** ë‚­ë…í•˜ì„¸ìš”.
- **Pacing**: ${speed !== 1.0 ? `Delivered at a ${speed}x pace.` : 'Natural and conversational.'}

[Text to Read - ì´ ${numLines}ì¤„]
${processedPrompt}

[ëŒ€ë³¸ ë - ì—¬ê¸°ê¹Œì§€ ëª¨ë“  ê¸€ìë¥¼ ë‹¤ ì½ì–´ì•¼ í•©ë‹ˆë‹¤]`;
      } else {
        finalPrompt = `${contextPrefix}[Precision TTS Mode]
Read the following text EXACTLY as written. DO NOT skip any words, sentences, or punctuation. DO NOT add any filler words or change the wording.

[Strict Instructions]
1. Read the text EXACTLY as written in the [Text to Read] section.
2. DO NOT skip any words like "ë˜ë°•ë˜ë°•" or "í•œ íš". Every word is essential.
3. **Voice Consistency & Quality**: Maintain a strictly consistent voice.
${instructions.map((inst, idx) => `${idx + 4}. ${inst}`).join('\n')}

[Text to Read]
${processedPrompt}`;
      }
    } else {
      // Even if no instructions, add context and strict precision rules
      finalPrompt = `${contextPrefix}[ì´ˆì •ë°€ TTS ëª¨ë“œ: ì•„ë˜ ëŒ€ë³¸ ${numLines}ì¤„ì˜ ëª¨ë“  ë‹¨ì–´ë¥¼ í•œ ê¸€ìë„ ë¹ ì§ì—†ì´ ì •í™•íˆ ê·¸ëŒ€ë¡œ ë‚­ë…í•˜ì„¸ìš”. ì ˆëŒ€ë¡œ ë‹¨ì–´ë¥¼ ìƒëµí•˜ê±°ë‚˜ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”.]\n\n${processedPrompt}\n\n[ëŒ€ë³¸ ë - ì—¬ê¸°ê¹Œì§€ ëª¨ë‘ ì½ì–´ì£¼ì„¸ìš”]`;
    }

    if (!generalAI || !liveAI) {
      throw new Error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
    }

    // --- CASE 1: Multimodal Live API (WebSocket) for Native Audio Dialog ---
    if (isNativeAudio) {
      console.log(`[Gemini Live API] Delegating to Multi-Turn generator...`);
      const lines = processedPrompt.split('\n').filter(l => l.trim().length > 0);
      const voiceInfo = speechConfig.voiceConfig?.prebuiltVoiceConfig.voiceName || 'Kore';

      const result = await generateAudioWithLiveAPIMultiTurn(
        lines,
        voiceInfo,
        stylePrompt || "Professional Korean Voice Narrator",
        speed,
        500, // Default 500ms silence
        signal
      );

      return uint8ArrayToBase64(new Uint8Array(result.audioBuffer));
    }

    // --- CASE 2: Standard REST API (generateContent) for Flash/Pro TTS ---
    // Use unified SDK style: generalAI.models.generateContent
    console.log(`[Gemini API Request] Model: ${modelName}, Prompt Length: ${finalPrompt.length}`);

    const result = await (generalAI as any).models.generateContent({
      model: modelName,
      contents: [{ role: 'user', parts: [{ text: finalPrompt }] }],
      config: {
        responseModalities: ['AUDIO'],
        speechConfig: isNativeAudio ? undefined : speechConfig,
        generationConfig: {
          temperature: 0.2, // Balance between voice consistency and emotional richness
        }
      },
      safetySettings: [
        { category: 'HARM_CATEGORY_HARASSMENT' as any, threshold: 'BLOCK_NONE' as any },
        { category: 'HARM_CATEGORY_HATE_SPEECH' as any, threshold: 'BLOCK_NONE' as any },
        { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT' as any, threshold: 'BLOCK_NONE' as any },
        { category: 'HARM_CATEGORY_DANGEROUS_CONTENT' as any, threshold: 'BLOCK_NONE' as any },
        { category: 'HARM_CATEGORY_CIVIC_INTEGRITY' as any, threshold: 'BLOCK_NONE' as any },
      ]
    });

    const response = result; // result inside (generalAI as any).models.generateContent is the parsed response directly

    console.log("[Gemini API Full Response]", JSON.stringify(response, null, 2));

    const candidate = response.candidates?.[0];

    // Check finishReason
    if (candidate?.finishReason && candidate.finishReason !== 'STOP' && candidate.finishReason !== 'MAX_TOKENS') {
      console.warn(`[Gemini TTS] Unusual finishReason: ${candidate.finishReason}. Audio might be truncated.`);
    }

    const audioPart = candidate?.content?.parts.find((part: any) => part.inlineData);
    const data = audioPart?.inlineData?.data;

    if (!data) {
      console.error("API response missing audio. Full candidate:", JSON.stringify(candidate, null, 2));

      if (candidate?.finishReason === 'SAFETY') {
        throw new Error(`ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. (FinishReason: SAFETY). ë¬¸ì œê°€ ëœ í…ìŠ¤íŠ¸ ì¼ë¶€: "${prompt.substring(0, 100)}..."`);
      }
      if (candidate?.finishReason === 'PROHIBITED_CONTENT') {
        const blockPreview = prompt.length > 500 ? prompt.substring(0, 500) + "..." : prompt;
        console.error("ì°¨ë‹¨ëœ í…ìŠ¤íŠ¸ ì²­í¬ ì „ì²´:", prompt);
        throw new Error(`êµ¬ê¸€ ì •ì±…ì— ì˜í•´ ì°¨ë‹¨ëœ ì½˜í…ì¸ ì…ë‹ˆë‹¤. (FinishReason: PROHIBITED_CONTENT). í•´ë‹¹ ì²­í¬ì— í¬í•¨ëœ íŠ¹ì • ë‹¨ì–´ë‚˜ í‘œí˜„ì„ ìˆ˜ì •í•´ ë³´ì„¸ìš”. (ì°¨ë‹¨ëœ êµ¬ê°„ ì‹œì‘: "${blockPreview}")`);
      }
      if (candidate?.finishReason === 'RECITATION') {
        throw new Error(`ì €ì‘ê¶Œì´ ìˆëŠ” í…ìŠ¤íŠ¸ë¡œ ê°ì§€ë˜ì–´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. (FinishReason: RECITATION).`);
      }
      if (candidate?.finishReason === 'OTHER') {
        throw new Error(`ì•Œ ìˆ˜ ì—†ëŠ” ì´ìœ ë¡œ ëª¨ë¸ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. (FinishReason: OTHER).`);
      }

      const textPart = candidate?.content?.parts?.[0]?.text;
      if (textPart) {
        console.warn("Model responded with text instead of audio:", textPart);
        throw new Error(`AIê°€ ì˜¤ë””ì˜¤ ëŒ€ì‹  í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤: "${textPart.substring(0, 150)}..."`);
      }

      // Check if parts exist but are just empty or weird
      const parts = candidate?.content?.parts;
      if (parts && parts.length > 0) {
        console.error("Parts found but no inlineData:", JSON.stringify(parts, null, 2));
      }

      throw new Error(`ì˜¤ë””ì˜¤ ë°ì´í„° ëˆ„ë½ (FinishReason: ${candidate?.finishReason || 'UNKNOWN'}). API ì‘ë‹µ êµ¬ì¡°ê°€ í‰ì†Œì™€ ë‹¤ë¦…ë‹ˆë‹¤. ì½˜ì†” ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.`);
    }

    return data;
  } catch (error) {
    if (error instanceof Error && error.name === 'AbortError') {
      throw error;
    }
    console.error("Error generating audio with Gemini API:", error);
    throw handleApiError(error);
  }
}

export const generateSingleSpeakerAudio = (
  prompt: string,
  voiceName: string,
  modelName: string,
  speed: number = 1.0,
  toneLevel: number = 3,
  stylePrompt?: string,
  signal?: AbortSignal
): Promise<string> => {
  const speechConfig: SpeechConfig = {
    voiceConfig: {
      prebuiltVoiceConfig: {
        voiceName: voiceName,
      },
    },
    languageCode: 'ko-KR',
  };
  return _generateAudio(prompt, modelName, speechConfig, speed, toneLevel, stylePrompt, signal);
};

export const previewVoice = (voiceName: string): Promise<string> => {
  const sampleText = `ì•ˆë…•í•˜ì„¸ìš”, ì´ê²ƒì€ ì œ ëª©ì†Œë¦¬ì…ë‹ˆë‹¤. ì´ ëª©ì†Œë¦¬ë¡œ ë©‹ì§„ ì˜¤ë””ì˜¤ ì½˜í…ì¸ ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`;
  // Use default Flash model for previews to save cost/latency
  const defaultModel = "gemini-2.5-flash-preview-tts";
  return generateSingleSpeakerAudio(sampleText, voiceName, defaultModel, 1.0);
};

export const transcribeAudioWithSrt = async (
  base64Wav: string,
  splitCharCount: number,
  signal?: AbortSignal,
  referenceText?: string,
  speed: number = 1.0
): Promise<string> => {
  if (!generalAI) {
    throw new Error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìš°ì¸¡ ìƒë‹¨ ì„¤ì • ì•„ì´ì½˜ì„ ëˆŒëŸ¬ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.");
  }

  try {
    const audioPart = {
      inlineData: {
        mimeType: 'audio/wav',
        data: base64Wav,
      },
    };

    const processedReference = referenceText
      ?.replace(/\.\.\./g, ', ')
      .replace(/â€¦/g, ', ');
    const numLinesSrt = processedReference?.split('\n').filter(l => l.trim()).length || 'N';

    let promptText = `ì—­í• : ì´ˆì •ë°€ ìë§‰ ì œì‘ì (Ultra-Precise Subtitler)
ëª©í‘œ: ì œê³µëœ [ëŒ€ë³¸ ì •ë³´]ì™€ [ì˜¤ë””ì˜¤]ë¥¼ 1:1ë¡œ ë§¤ì¹­í•˜ì—¬ ì™„ë²½í•œ SRT ìƒì„± (ì ˆëŒ€ ì¤„ì„ í•©ì¹˜ê±°ë‚˜ ë‚˜ëˆ„ì§€ ë§ ê²ƒ)

[ì§€ì¹¨]
1. ì…ë ¥ ëŒ€ë³¸ì˜ ì´ ì¤„ ìˆ˜ëŠ” ì •í™•íˆ **${numLinesSrt}ì¤„**ì…ë‹ˆë‹¤.
2. **ë§¤ìš° ì¤‘ìš”**: ê° ì¤„ì€ ì‰¼í‘œ(,)ë‚˜ ë§ˆì¹¨í‘œ(.)ê°€ ìˆë”ë¼ë„ ì ˆëŒ€ ë‘ ê°œ ì´ìƒì˜ SRT ì—”íŠ¸ë¦¬ë¡œ ë‚˜ëˆ„ì§€ ë§ˆì‹­ì‹œì˜¤.
3. ì…ë ¥ ë°ì´í„°ì˜ 1ë²ˆ ì¤„ì€ ë¬´ì¡°ê±´ SRTì˜ 1ë²ˆ, 2ë²ˆ ì¤„ì€ SRTì˜ 2ë²ˆì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
4. ì˜ˆ: "í•œ íš, í•œ íš, ë˜ë°•ë˜ë°• ì¨ ë‚´ë ¤ê°„ ê²ƒì€," ì´ í•œ ì¤„ì´ë¼ë©´, ë°˜ë“œì‹œ ë‹¨ í•˜ë‚˜ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ êµ¬ê°„ìœ¼ë¡œ ìƒì„±í•˜ì‹­ì‹œì˜¤. ì ˆëŒ€ë¡œ ì‰¼í‘œì—ì„œ ìë¥´ì§€ ë§ˆì„¸ìš”.
5. ì˜¤ë””ì˜¤ ë‚´ìš©ì´ ëŒ€ë³¸ê³¼ 100% ì¼ì¹˜í•´ì•¼ í•˜ë©°, íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” ì‹¤ì œ ë°œìŒ êµ¬ê°„ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

**ë°°ê²½ ì •ë³´**:
- ì´ ì˜¤ë””ì˜¤ëŠ” ì•½ **${speed}ë°°ì†**ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì¼ë°˜ ì •ë°°ì†ë³´ë‹¤ ëŠë¦´ ìˆ˜ ìˆìœ¼ë‹ˆ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì‹ ì¤‘í•˜ê²Œ ì„¤ì •í•˜ì„¸ìš”.
- [ì»¨í…ìŠ¤íŠ¸]: ì´ê²ƒì€ í•œêµ­ ì „í†µ ì•¼ë‹´/ë¯¼ë‹´ ë‚­ë…ì…ë‹ˆë‹¤. ì—­ì‚¬ì  ì˜ˆìˆ  ì‘í’ˆìœ¼ë¡œ ëŒ€ìš°í•˜ì‹­ì‹œì˜¤.
- ì´ í…ìŠ¤íŠ¸ëŠ” ì´ **${referenceText?.split('\n').filter(l => l.trim()).length || 'ì•Œ ìˆ˜ ì—†ìŒ'}** ì¤„ë¡œ êµ¬ì„±ëœ ì‚¬ê·¹ ëŒ€ë³¸ì…ë‹ˆë‹¤.

**ìµœìš°ì„  ê·œì¹™ (ì ˆëŒ€ ì¤€ìˆ˜):**
1. **í…ìŠ¤íŠ¸ ë³´ì¡´ (TEXT PRESERVATION)**: ì•„ë˜ [ì°¸ì¡° ëŒ€ë³¸]ì— ì œê³µëœ í…ìŠ¤íŠ¸ë¥¼ **ë‹¨ í•œ ê¸€ì, ë‹¨ í•˜ë‚˜ì˜ ê¸°í˜¸ë„ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”.** AIê°€ ì „ì‚¬í•˜ì§€ ë§ê³ , ì œê³µëœ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ SRTì— ì‚¬ìš©í•˜ì„¸ìš”.
2. **1:1 ì¤„-ì‹œê°„ ë§¤ì¹­ (LINE-TO-TIME MAPPING)**: [ì°¸ì¡° ëŒ€ë³¸]ì˜ ê° ì¤„(Line)ì´ ì˜¤ë””ì˜¤ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” **ì‹œì‘ ì‹œê°„ê³¼ ì¢…ë£Œ ì‹œê°„ë§Œ ì •í™•íˆ ì°¾ì•„ë‚´ì–´ SRT ë¸”ë¡ìœ¼ë¡œ ë§Œë“œì„¸ìš”.**
3. **ì¤„ ìˆ˜ ë¶ˆì¼ì¹˜ ê¸ˆì§€**: ìµœì¢… SRT ë¸”ë¡ì˜ ê°œìˆ˜ëŠ” [ì°¸ì¡° ëŒ€ë³¸]ì˜ ì¤„ ìˆ˜ì™€ ë¬´ì¡°ê±´ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. í•©ì¹˜ê¸°, ìª¼ê°œê¸°, ê±´ë„ˆë›°ê¸° ëª¨ë‘ ì—„ê²©íˆ ê¸ˆì§€í•©ë‹ˆë‹¤.
4. **í¬ë§· ì¤€ìˆ˜**: í‘œì¤€ SubRip(.srt) í˜•ì‹ì„ ë”°ë¥´ë˜, ë‚´ìš©ì€ ë°˜ë“œì‹œ ì œê³µëœ ëŒ€ë³¸ì„ í† ì”¨ í•˜ë‚˜ í‹€ë¦¬ì§€ ì•Šê³  ì‚¬ìš©í•˜ì„¸ìš”.
5. **íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë°€ë„**: 0.9ë°°ì† ì˜¤ë””ì˜¤ íŒŒí˜•ì— ë§ì¶° ë¬¸ì¥ì´ ì‹œì‘ë˜ê³  ëë‚˜ëŠ” ì§€ì ì„ ë°€ë¦¬ì´ˆ ë‹¨ìœ„ë¡œ ì •í™•íˆ ì¡ìœ¼ì„¸ìš”.

**[ì°¸ì¡° ëŒ€ë³¸]:**
${referenceText}

**ì¶œë ¥**: ì½”ë“œ ë¸”ë¡(\`\`\`srt) ì•ˆì— SRT ë‚´ìš©ë§Œ ì¶œë ¥í•˜ì„¸ìš”.`;

    if (referenceText) {
      promptText += `

**[ëª¨ë“œ: ê°•ì œ ì •ë ¬ (Forced Alignment)]**
**ë°°ê²½**: ì´ ì˜¤ë””ì˜¤ëŠ” ì°½ì‘ ì‚¬ê·¹ ë“œë¼ë§ˆì˜ ì¼ë¶€ì…ë‹ˆë‹¤.
ì œê³µëœ **ì°¸ì¡° ìŠ¤í¬ë¦½íŠ¸**ê°€ ì´ ì˜¤ë””ì˜¤ì˜ ì •í™•í•œ ëŒ€ë³¸ì…ë‹ˆë‹¤. ì´ ìŠ¤í¬ë¦½íŠ¸ì˜ ëª¨ë“  ì¤„ì„ ì˜¤ë””ì˜¤ íŒŒí˜•ê³¼ ì¼ì¹˜ì‹œì¼œ SRTë¥¼ ìƒì„±í•˜ì„¸ìš”.

**â˜… ì¤‘ìš” ìë§‰ ê·œì¹™ (í•„ë…):**
1. **ëˆ„ë½ ê¸ˆì§€:** ì°¸ì¡° ìŠ¤í¬ë¦½íŠ¸ì˜ ëª¨ë“  ë¬¸ì¥ì„ ì˜ˆì™¸ ì—†ì´ ìë§‰ìœ¼ë¡œ ë§Œë“œì„¸ìš”.
2. **ì²« ë¬¸ì¥ (0ì´ˆ ì‹œì‘):** ì²« ìë§‰ì€ ë¬´ì¡°ê±´ 00:00:00,000ì—ì„œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
3. **ê²¹ì¹¨ ë°©ì§€:** (N)ë²ˆì§¸ ìë§‰ ì¢…ë£Œ ì‹œê°„ < (N+1)ë²ˆì§¸ ìë§‰ ì‹œì‘ ì‹œê°„ì´ ë˜ë„ë¡ í•˜ì„¸ìš”.
4. **ê°€ë…ì„± ë¶„í• :** í•œ ì¤„ì´ ë„ˆë¬´ ê¸¸ë©´(${splitCharCount}ì ì´ìƒ) ì˜ë¯¸ ë‹¨ìœ„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‘ ì¤„ë¡œ ë‚˜ëˆ„ì„¸ìš”.

**[ì°¸ì¡° ìŠ¤í¬ë¦½íŠ¸]:**
${referenceText}`;
    } else {
      promptText += `

**[ëª¨ë“œ: ì¼ë°˜ ì „ì‚¬ (Transcription)]**
1. ì˜¤ë””ì˜¤ë¥¼ ë“£ê³  ë‚´ìš©ì„ ì •í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ë°›ì•„ì“°ì„¸ìš”.
2. ë¬¸ë§¥ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì¤„ì„ ë‚˜ëˆ„ì–´ ìë§‰ì„ ìƒì„±í•˜ì„¸ìš”.
3. ìë§‰ í•œ ì¤„ì€ ìµœëŒ€ ${splitCharCount}ìë¥¼ ë„˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.
`;
    }

    promptText += `

**ì¶œë ¥ ì˜ˆì‹œ:**
1
00:00:00,000 --> 00:00:02,150
ì•ˆë…•í•˜ì„¸ìš”! AI ë³´ì´ìŠ¤ ìŠ¤íŠœë””ì˜¤ì…ë‹ˆë‹¤.

2
00:00:02,250 --> 00:00:05,100
í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ëª©ì†Œë¦¬ë¡œ ë³€í™˜í•´ë“œë¦½ë‹ˆë‹¤.
`;

    const textPart = { text: promptText };

    // âœ… ì‹ ë²„ì „ ë¬¸ë²• + gemini-2.5-flash
    const result = await (generalAI as any).models.generateContent({
      model: 'gemini-2.5-flash',
      contents: [{
        role: 'user',
        parts: [audioPart, textPart]
      }],
      safetySettings: [
        { category: 'HARM_CATEGORY_HARASSMENT' as any, threshold: 'BLOCK_NONE' as any },
        { category: 'HARM_CATEGORY_HATE_SPEECH' as any, threshold: 'BLOCK_NONE' as any },
        { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT' as any, threshold: 'BLOCK_NONE' as any },
        { category: 'HARM_CATEGORY_DANGEROUS_CONTENT' as any, threshold: 'BLOCK_NONE' as any },
        { category: 'HARM_CATEGORY_CIVIC_INTEGRITY' as any, threshold: 'BLOCK_NONE' as any },
      ]
    });

    // âœ… ì‘ë‹µ ì ‘ê·¼
    let srtText = result.candidates?.[0]?.content?.parts?.[0]?.text?.trim() ?? '';

    const match = srtText.match(/```(?:srt)?\s*([\s\S]*?)```/);
    if (match && match[1]) {
      srtText = match[1].trim();
    }

    return srtText;
  } catch (error) {
    if (error instanceof Error && error.name === 'AbortError') {
      throw error;
    }
    console.error("Error transcribing audio with Gemini API:", error);
    throw handleApiError(error);
  }
};

/**
 * Live API ë‹¨ì¼ ì„¸ì…˜ ë©€í‹°í„´ ë°©ì‹ìœ¼ë¡œ ì˜¤ë””ì˜¤ ìƒì„±
 * - ì„¸ì…˜ 1ê°œ ìœ ì§€
 * - ì¤„ë³„ë¡œ ë…ë¦½ í„´ ìš”ì²­
 * - ê° ì¤„ ì™„ë£Œ í›„ ë‹¤ìŒ ì¤„ ì§„í–‰
 */
export async function generateAudioWithLiveAPIMultiTurn(
  lines: string[],
  voiceName: string,
  stylePrompt: string,
  speed: number = 1.0,
  silenceBetweenLinesMs: number = 500,
  signal?: AbortSignal
): Promise<{
  audioBuffer: ArrayBuffer;
  lineTimings: { start: number; end: number }[];
  paragraphs: string[];
}> {

  if (!liveAI) {
    throw new Error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
  }

  const audioResults: ArrayBuffer[] = [];
  const lineTimings: { start: number; end: number }[] = [];
  let currentLineAudio: ArrayBuffer[] = [];
  let turnCompleteResolve: (() => void) | null = null;
  let sessionError: Error | null = null;
  let chunkCounter = 0; // ì„¸ì…˜ ì „ì²´ ì²­í¬ ì¹´ìš´í„°

  // ìœ íš¨í•œ ì¤„ë§Œ í•„í„°ë§
  const validLines = lines.map(l => l.trim()).filter(l => l.length > 0);

  if (lines.length === 0) {
    throw new Error("ìƒì„±í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.");
  }

  console.log(`[Gemini Live API] Starting Precision Paragraph-Based Multi-Turn session`);

  // ë¹ˆ ì¤„ì„ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ë‹¨(Batch) ë‚˜ëˆ„ê¸°
  const paragraphs: string[] = [];
  let currentGroup: string[] = [];

  for (const line of lines) {
    if (line.trim().length === 0) {
      if (currentGroup.length > 0) {
        paragraphs.push(currentGroup.join('\n'));
        currentGroup = [];
      }
    } else {
      currentGroup.push(line);
    }
  }
  if (currentGroup.length > 0) {
    paragraphs.push(currentGroup.join('\n'));
  }

  if (paragraphs.length === 0) {
    throw new Error("ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.");
  }

  console.log(`[Gemini Live API] Processing ${paragraphs.length} paragraphs`);

  return new Promise(async (resolve, reject) => {
    try {
      const liveModel = 'gemini-2.5-flash-native-audio-preview-12-2025';
      const session = await (liveAI as any).live.connect({
        model: liveModel,
        config: {
          responseModalities: [Modality.AUDIO],
          speechConfig: {
            voiceConfig: {
              prebuiltVoiceConfig: {
                voiceName,
              }
            }
          },
          systemInstruction: {
            parts: [{
              text: `[System Instruction]: You are a professional Korean voice actor. 
[Voice Persona]: Warm, calm, and steady late-night radio DJ. Use de-essed, smooth vocal texture.
[Director's Notes]: ${stylePrompt}
[Strict Rules]: 
1. Read the provided text EXACTLY as written. 
2. DO NOT skip any words, symbols, or sentences. 
3. Output ONLY the spoken audio. 
4. DO NOT summarize or interpret.`
            }]
          },
          safetySettings: [
            { category: 'HARM_CATEGORY_HARASSMENT' as any, threshold: 'BLOCK_NONE' as any },
            { category: 'HARM_CATEGORY_HATE_SPEECH' as any, threshold: 'BLOCK_NONE' as any },
            { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT' as any, threshold: 'BLOCK_NONE' as any },
            { category: 'HARM_CATEGORY_DANGEROUS_CONTENT' as any, threshold: 'BLOCK_NONE' as any },
            { category: 'HARM_CATEGORY_CIVIC_INTEGRITY' as any, threshold: 'BLOCK_NONE' as any },
          ],
        },
        callbacks: {
          onopen: () => {
            console.log('[Gemini Live API] WebSocket opened.');
          },
          onmessage: async (response: any) => {
            const isTurnComplete = !!response.serverContent?.turnComplete;

            // ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì§‘
            if (response.serverContent?.modelTurn?.parts) {
              for (const part of response.serverContent.modelTurn.parts) {
                if (part.inlineData?.data) {
                  const chunk = base64ToArrayBuffer(part.inlineData.data);
                  // ì•ˆì •ì„±ì„ ìœ„í•´ ìµœì†Œí•œì˜ ë¡œê·¸ ì¶œë ¥ ìœ ì§€ (ë¡œê·¸ ì¶œë ¥ ì‹œ ë°œìƒí•˜ëŠ” ë¯¸ì„¸ ì§€ì—°ì´ ìˆ˜ì§‘ ì•ˆì •í™”ì— ë„ì›€)
                  console.log(`[Gemini Live API] Chunk received: ${chunk.byteLength} bytes`);
                  currentLineAudio.push(chunk);
                }
              }
            }

            // í„´ ì™„ë£Œ ê°ì§€ (800ms ëŒ€ê¸°í•˜ì—¬ ë§ˆì§€ë§‰ ì²­í¬ ìˆ˜ì‹  ë³´ì¥)
            if (isTurnComplete) {
              console.log(`[Gemini Live API] turnComplete received. Starting 800ms protection delay...`);
              const resolveRef = turnCompleteResolve;
              turnCompleteResolve = null;
              if (resolveRef) {
                setTimeout(() => {
                  console.log(`[Gemini Live API] 800ms delay finished. Resolving turn.`);
                  resolveRef();
                }, 800);
              }
            }

            // ì¸í„°ëŸ½íŠ¸ ê°ì§€
            if (response.serverContent?.interrupted) {
              console.warn(`[Gemini Live API] Server sent "interrupted" signal. Waiting for turnComplete anyway...`);
            }
          },
          onerror: (e: any) => {
            console.error('[Gemini Live API] Error:', e);
            sessionError = new Error(e.message || 'Live API ì˜¤ë¥˜');
            if (turnCompleteResolve) {
              turnCompleteResolve();
            }
          },
          onclose: (e: any) => {
            console.log(`[Gemini Live API] WebSocket closed. (Code ${e?.code || 'unknown'})`);
          }
        }
      });

      // ì„¸ì…˜ ì—°ê²° ì™„ë£Œ í›„ ë©€í‹°í„´ ì²˜ë¦¬ ì‹œì‘
      console.log('[Gemini Live API] Connected. Starting multi-turn loop...');

      let cumulativeTimeMs = 0;

      for (let i = 0; i < paragraphs.length; i++) {
        // ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
        if (signal?.aborted) {
          session.close();
          throw new Error('ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.');
        }

        const batchText = paragraphs[i];

        // ë§ì¤„ì„í‘œ ì¹˜í™˜ ëŒ€ì‹  ì›ë³¸ í…ìŠ¤íŠ¸ ìœ ì§€ (ì‚¬ìš©ìë‹˜ ê´€ì°° ë°˜ì˜)
        const processedBatch = batchText;

        console.log(`[Gemini Live API] Requesting Paragraph ${i + 1}/${paragraphs.length}: "${processedBatch.substring(0, 30).replace(/\n/g, ' ')}..."`);

        // í˜„ì¬ ì¤„ ì˜¤ë””ì˜¤ ì´ˆê¸°í™” ë° ì²­í¬ ì¹´ìš´í„° ë¦¬ì…‹
        currentLineAudio = [];
        chunkCounter = 0;

        // í„´ ì™„ë£Œ ëŒ€ê¸° Promise ìƒì„±
        const turnCompletePromise = new Promise<void>((res) => {
          turnCompleteResolve = res;
        });

        // Send the batch with a clear instruction
        const linePrompt = `Please read this text exactly: "${processedBatch}"`;

        await session.sendClientContent({
          turns: [{ role: 'user', parts: [{ text: linePrompt }] }],
          turnComplete: true
        });

        // í„´ ì™„ë£Œ ëŒ€ê¸°
        await turnCompletePromise;

        // ì—ëŸ¬ ì²´í¬
        if (sessionError) {
          session.close();
          throw sessionError;
        }

        // ê²°ê³¼ ì €ì¥
        const lineAudio = mergeArrayBuffers(currentLineAudio);
        audioResults.push(lineAudio);

        // íƒ€ì´ë° ê³„ì‚° (24kHz, 16bit ê¸°ì¤€)
        // Note: Gemini standard sampling rate for Native Audio is often 24kHz or 16kHz. 
        // We'll use 24kHz as per user instructions.
        const lineDurationMs = (lineAudio.byteLength / 2 / 24000) * 1000;
        lineTimings.push({
          start: cumulativeTimeMs,
          end: cumulativeTimeMs + lineDurationMs
        });
        cumulativeTimeMs += lineDurationMs + silenceBetweenLinesMs;

        console.log(`[Gemini Live API] Line ${i + 1} completed. ${lineAudio.byteLength} bytes, ${lineDurationMs.toFixed(0)}ms`);
      }

      // ì„¸ì…˜ ì¢…ë£Œ
      session.close();

      // ë¬´ìŒ ì‚½ì…í•˜ì—¬ ìµœì¢… ë³‘í•©
      console.log(`[Gemini Live API] Merging ${audioResults.length} audio segments with ${silenceBetweenLinesMs}ms silence...`);
      const finalAudio = mergeAudioWithSilence(audioResults, silenceBetweenLinesMs);

      console.log(`[Gemini Live API] Complete! Total: ${finalAudio.byteLength} bytes`);

      resolve({
        audioBuffer: finalAudio,
        lineTimings: lineTimings,
        paragraphs: paragraphs
      });

    } catch (error) {
      reject(error);
    }
  });
}

/**
 * Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìº¡ì»· ìë§‰ê³¼ ì›ë³¸ ëŒ€ë³¸ì„ AI ì¶”ë¡ ìœ¼ë¡œ ë§¤ì¹­
 * @param capCutSrtText ìº¡ì»· SRT í…ìŠ¤íŠ¸ (ë²ˆí˜¸, íƒ€ì„ì½”ë“œ í¬í•¨)
 * @param scriptLines ì›ë³¸ ìë§‰ ë¼ì¸ ë°°ì—´
 * @returns ë§¤ì¹­ ê²°ê³¼ JSON ë°°ì—´
 */
export async function matchSubtitlesWithAI(
  capCutSrtLines: Array<{ index: number; text: string }>,
  scriptLines: Array<{ index: number; text: string }>,
  onProgress?: (status: string) => void
): Promise<Array<{ scriptIndex: number; capCutStartIndex: number; capCutEndIndex: number }>> {
  if (!generalAI) {
    throw new Error('Gemini APIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.');
  }

  // ë°°ì¹˜ ì²˜ë¦¬ (SDK ì œí•œìœ¼ë¡œ ì¸í•´ í•œ ë²ˆì— ì²˜ë¦¬ ë¶ˆê°€)
  const BATCH_SIZE = 100;
  const totalBatches = Math.ceil(scriptLines.length / BATCH_SIZE);
  const allMatches: Array<{ scriptIndex: number; capCutStartIndex: number; capCutEndIndex: number }> = [];

  console.log(`[AI Matching] ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: ${totalBatches}ê°œ ë°°ì¹˜`);
  onProgress?.(` AI ë§¤ì¹­ ì¤€ë¹„ì¤‘... (${scriptLines.length}ì¤„)`);

  for (let batchIndex = 0; batchIndex < totalBatches; batchIndex++) {
    const startIdx = batchIndex * BATCH_SIZE;
    const endIdx = Math.min(startIdx + BATCH_SIZE, scriptLines.length);
    const batchScriptLines = scriptLines.slice(startIdx, endIdx);

    const progress = `AI ë§¤ì¹­ ì¤‘ (${batchIndex + 1}/${totalBatches})... ${startIdx + 1}~${endIdx}ì¤„`;
    console.log(`[AI Matching] ${progress}`);
    onProgress?.(progress);

    // ì´ì „ ë°°ì¹˜ì˜ ë§ˆì§€ë§‰ ìº¡ì»· ì¸ë±ìŠ¤ ê³„ì‚°
    const lastCapCutIndex = allMatches.length > 0
      ? Math.max(...allMatches.map(m => m.capCutEndIndex)) + 1
      : 0;

    // í”„ë¡¬í”„íŠ¸ ìƒì„± (í˜„ì¬ ë°°ì¹˜ë§Œ)
    const capCutText = capCutSrtLines
      .slice(lastCapCutIndex)
      .map(line => `[${line.index}] ${line.text}`)
      .join('\n');

    const scriptText = batchScriptLines
      .map(line => `[${line.index}] ${line.text}`)
      .join('\n');

  const prompt = `ë‹¹ì‹ ì€ ì˜ìƒ ìë§‰ íƒ€ì„ì½”ë“œ ë§¤ì¹­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ë°°ê²½:**
- ì›ë³¸ ëŒ€ë³¸: ë‚˜ë ˆì´ì…˜ìš©ìœ¼ë¡œ ì‘ì„±ëœ ì™„ì „í•œ ìŠ¤í¬ë¦½íŠ¸
- ìº¡ì»· SRT: ì‹¤ì œ ë‚˜ë ˆì´ì…˜ ìŒì„±ì„ ìë™ ì¸ì‹í•˜ì—¬ ìƒì„±ëœ ìë§‰ (íƒ€ì„ì½”ë“œ í¬í•¨)
- ëª©í‘œ: ì›ë³¸ ëŒ€ë³¸ì„ í™”ë©´ ìë§‰ìœ¼ë¡œ í‘œì‹œí•˜ë˜, ìº¡ì»· SRTì˜ ì •í™•í•œ íƒ€ì„ì½”ë“œë¥¼ ì‚¬ìš©

**ì‘ì—… ëª©í‘œ:**
ì›ë³¸ ëŒ€ë³¸ì˜ ê° ë¼ì¸ì´ ë‚˜ë ˆì´ì…˜ì´ ì½ê³  í™”ë©´ ìë§‰ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ì ì ˆí•˜ë„ë¡,
ìº¡ì»· SRTì˜ íƒ€ì„ì½”ë“œë¥¼ ì •í™•íˆ ë§¤ì¹­í•˜ì„¸ìš”.
ì›ë³¸ ëŒ€ë³¸ì´ ë¶ˆí•„ìš”í•˜ê²Œ ì¤„ë°”ê¿ˆë˜ì–´ ë„ˆë¬´ ì§§ë‹¤ë©´ í™”ë©´ ìë§‰ì„ ê³ ë ¤í•˜ì—¬ í•œ ì¤„ë¡œ í•©ì³ì£¼ì„¸ìš”.

**ë§¤ì¹­ ê·œì¹™:**
1. ìˆœì„œëŠ” ì•ì—ì„œë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤ (ì ˆëŒ€ ë’¤ë¡œ ê°€ì§€ ì•ŠìŒ)
2. ì›ë³¸ ëŒ€ë³¸ 1ì¤„ = ìº¡ì»· Nì¤„ ë§¤ì¹­ ê°€ëŠ¥ (1â†’N, ì˜ˆ: ëŒ€ë³¸ 34 = ìº¡ì»· 76~78)
3. ì›ë³¸ ëŒ€ë³¸ Nì¤„ = ìº¡ì»· 1ì¤„ ë§¤ì¹­ ê°€ëŠ¥ (Nâ†’1, ì˜ˆ: ëŒ€ë³¸ 54+55 = ìº¡ì»· 110)
4. ìŒì„± ì¸ì‹ ì˜¤ë¥˜, ë„ì–´ì“°ê¸° ì°¨ì´, ì˜ì—­ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ë§¤ì¹­
5. ëª¨ë“  ì›ë³¸ ëŒ€ë³¸ ë¼ì¸ì€ ë°˜ë“œì‹œ ë§¤ì¹­ë˜ì–´ì•¼ í•¨

**ì¶”ê°€ ì‘ì—… - ì§§ì€ ë¬¸ì¥ í•©ì¹˜ê¸°:**
ì›ë³¸ ëŒ€ë³¸ì— ë¶ˆí•„ìš”í•˜ê²Œ ì§§ì€ ë¬¸ì¥ì´ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ë‰˜ì–´ ìˆëŠ” ê²½ìš°,
ìì—°ìŠ¤ëŸ¬ìš´ í•œ ë¬¸ì¥/ë¬¸ë‹¨ìœ¼ë¡œ í•©ì³ì„œ ìº¡ì»· íƒ€ì„ì½”ë“œë¥¼ ë§¤ì¹­í•´ì£¼ì„¸ìš”.

í•©ì³ì§„ ê²½ìš°ì—ë„ ê° ì›ë³¸ ë¼ì¸ë§ˆë‹¤ JSON í•­ëª©ì„ ìƒì„±í•˜ë˜, ë™ì¼í•œ ìº¡ì»· ë²”ìœ„ë¥¼ ì§€ì •í•˜ì„¸ìš”.

ì˜ˆì‹œ:
  ì›ë³¸ [10]: "ì•ˆë…•í•˜ì„¸ìš”."
  ì›ë³¸ [11]: "ì˜¤ëŠ˜ì€"
  ì›ë³¸ [12]: "ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”."
  ìº¡ì»· [15]: "ì•ˆë…•í•˜ì„¸ìš” ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”"

  â†’ ì¶œë ¥:
  {"scriptIndex": 10, "capCutStartIndex": 15, "capCutEndIndex": 15},
  {"scriptIndex": 11, "capCutStartIndex": 15, "capCutEndIndex": 15},
  {"scriptIndex": 12, "capCutStartIndex": 15, "capCutEndIndex": 15}

**ì…ë ¥ ë°ì´í„°:**

ìº¡ì»· SRT (${capCutSrtLines.length - lastCapCutIndex}ì¤„, ì‹œì‘ ì¸ë±ìŠ¤: ${lastCapCutIndex}):
${capCutText}

ì›ë³¸ ìë§‰ë¶„í•  ëŒ€ë³¸ (${batchScriptLines.length}ì¤„, ì¸ë±ìŠ¤ ${startIdx}~${endIdx - 1}):
${scriptText}

**ì¶œë ¥ í˜•ì‹ (JSONë§Œ ë°˜í™˜, ì„¤ëª… ì—†ì´):**
ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
[
  {"scriptIndex": ${startIdx}, "capCutStartIndex": ${lastCapCutIndex}, "capCutEndIndex": ...},
  {"scriptIndex": ${startIdx + 1}, "capCutStartIndex": ..., "capCutEndIndex": ...}
]

scriptIndex: ì›ë³¸ ëŒ€ë³¸ ë¼ì¸ ë²ˆí˜¸ (${startIdx}ë¶€í„° ì‹œì‘)
capCutStartIndex: ë§¤ì¹­ë˜ëŠ” ì²« ë²ˆì§¸ ìº¡ì»· ë¼ì¸ ë²ˆí˜¸
capCutEndIndex: ë§¤ì¹­ë˜ëŠ” ë§ˆì§€ë§‰ ìº¡ì»· ë¼ì¸ ë²ˆí˜¸ (í¬í•¨)`;

    try {
      // Gemini API í˜¸ì¶œ (ì˜¬ë°”ë¥¸ íŒŒë¼ë¯¸í„° êµ¬ì¡°)
      const result = await (generalAI as any).models.generateContent({
        model: 'gemini-2.5-flash',
        contents: [{
          role: 'user',
          parts: [{ text: prompt }]
        }],
        generationConfig: {
          temperature: 0.1,
          topP: 0.95,
          topK: 40,
          maxOutputTokens: 65535  // Gemini 2.5 Flash ìµœëŒ€ ì¶œë ¥ í† í° (65K)
        },
        safetySettings: [
          { category: 'HARM_CATEGORY_HARASSMENT' as any, threshold: 'BLOCK_NONE' as any },
          { category: 'HARM_CATEGORY_HATE_SPEECH' as any, threshold: 'BLOCK_NONE' as any },
          { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT' as any, threshold: 'BLOCK_NONE' as any },
          { category: 'HARM_CATEGORY_DANGEROUS_CONTENT' as any, threshold: 'BLOCK_NONE' as any },
          { category: 'HARM_CATEGORY_CIVIC_INTEGRITY' as any, threshold: 'BLOCK_NONE' as any },
        ]
      });

      // ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
      let responseText = '';
      if (result?.candidates?.[0]?.content?.parts?.[0]?.text) {
        responseText = result.candidates[0].content.parts[0].text.trim();
      } else {
        throw new Error('AI ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      }

      // ìƒì„¸ ë¡œê¹… ì¶”ê°€
      const finishReason = result?.candidates?.[0]?.finishReason;
      console.log(`[AI Matching] ë°°ì¹˜ ${batchIndex + 1} ì‘ë‹µ ê¸¸ì´: ${responseText.length} ë¬¸ì`);
      console.log(`[AI Matching] ë°°ì¹˜ ${batchIndex + 1} finishReason: ${finishReason || 'UNKNOWN'}`);

      // finishReason ê²€ì¦
      if (finishReason && finishReason !== 'STOP') {
        console.warn(`[AI Matching] ë°°ì¹˜ ${batchIndex + 1} ê²½ê³ : finishReason = ${finishReason} (ì¡°ê¸° ì¢…ë£Œ ê°€ëŠ¥ì„±)`);
        if (finishReason === 'MAX_TOKENS') {
          console.error(`[AI Matching] ë°°ì¹˜ ${batchIndex + 1} í† í° ì œí•œ ì´ˆê³¼! maxOutputTokensë¥¼ ë” ëŠ˜ë ¤ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.`);
        }
      }

      // ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸° ë¡œê¹… (ì²˜ìŒ 200ì, ë§ˆì§€ë§‰ 200ì)
      if (responseText.length > 500) {
        const preview = {
          start: responseText.substring(0, 200),
          end: responseText.substring(responseText.length - 200)
        };
        console.log(`[AI Matching] ë°°ì¹˜ ${batchIndex + 1} ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°:`, preview);
      } else {
        console.log(`[AI Matching] ë°°ì¹˜ ${batchIndex + 1} ì „ì²´ ì‘ë‹µ:`, responseText);
      }

      // JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
      if (responseText.startsWith('```json')) {
        responseText = responseText.replace(/^```json\n/, '').replace(/\n```$/, '');
      } else if (responseText.startsWith('```')) {
        responseText = responseText.replace(/^```\n/, '').replace(/\n```$/, '');
      }

      // JSON íŒŒì‹±
      const batchMatches = JSON.parse(responseText);

      if (!Array.isArray(batchMatches)) {
        throw new Error('AI ì‘ë‹µì´ ë°°ì—´ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.');
      }

      console.log(`[AI Matching] ë°°ì¹˜ ${batchIndex + 1} âœ… ì„±ê³µ: ${batchMatches.length}ê°œ ë§¤ì¹­ ì™„ë£Œ`);

      // ê²°ê³¼ ëˆ„ì 
      allMatches.push(...batchMatches);

    } catch (error) {
      console.error(`[AI Matching] ë°°ì¹˜ ${batchIndex + 1} ì˜¤ë¥˜:`, error);
      throw new Error(`ë°°ì¹˜ ${batchIndex + 1} AI ë§¤ì¹­ ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
    }
  }

  console.log(`[AI Matching] âœ… ì „ì²´ ì™„ë£Œ: ${allMatches.length}ê°œ ë§¤ì¹­ ì™„ë£Œ`);
  onProgress?.(`AI ë§¤ì¹­ ì™„ë£Œ! (${allMatches.length}ê°œ)`);
  return allMatches;
}
